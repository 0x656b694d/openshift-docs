= Guidelines
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview
When creating Docker images to run on OpenShift, there are a number of best practices to consider as an image author to ensure a good experience for consumers of those images. Because images are intended to be immutable and used as is, it is your responsibility to ensure:

- the image contains any artifacts that would typically be needed by a user of the image, and
- the image can be configured by the user.

== General Docker Guidelines
The following are some guidelines that apply to Docker image creation in general, independent of whether the images are used on OpenShift. See the official https://docs.docker.com/articles/dockerfile_best-practices/[Docker documentation] for more comprehensive guidelines.

*Reusing Images*

Wherever possible, base your image on an appropriate upstream image using the `FROM` statement. This ensures your image can easily pick up security fixes from an upstream image when it is updated, rather than you being responsible for updating your dependencies directly.

In addition, use tags in the `FROM` instruction (for example,  `rhel:rhel7`) to make it clear to users exactly which version of an image your image is based on. Using a tag other than `latest` ensures your image is not subjected to breaking changes that might go into the `latest` version of an upstream image.

*Tagging Images*

When tagging your own images, strive to maintain backwards compatibility within a tag. For example, if you provide an image named [sysitem]#foo# and it currently includes version 1.0, you might provide a tag of _foo:v1_. When you update the image, as long as it continues to be compatible with the original image, you can continue to tag the new image _foo:v1_, and downstream consumers of this tag will be able to get updates without being broken.

If you later release an incompatible update, then you should switch to a new tag, for example _foo:v2_. This allows downstream consumers to move up to the new version at will, but not be inadvertently broken by the new incompatible image. Of course, any downstream consumer who chooses to use _foo:latest_ will be taking on the risk of any incompatible changes introduced.

*Avoiding Multiple Processes*

Do not start multiple services, such a database and [sysitem]#sshd#, inside one container. Containers are lightweight and can be easily linked together for multiprocess orchestration. OpenShift allows you to easily collocate and comanage related images by grouping them into a single pod.

This collocation ensures they share a network namespace and storage for communication. It also makes updates less disruptive as each image can be updated less frequently and independently. Having a single process also makes signal handling flows clearer as you do not need to manage routing signals to spawned processes.

*Using `exec` in Wrapper Scripts*

See the "Always `exec` in Wrapper Scripts" section of the http://www.projectatomic.io/docs/docker-image-author-guidance[Project Atomic documentation] for more information.

Also be aware that your process runs as PID 1 when running in a Docker container. This means that if your main process terminates, the entire container is stopped, killing any child processes you may have launched from your PID 1 process.

See the http://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/["Docker and the PID 1 zombie reaping problem"] blog article for additional implications. See the https://felipec.wordpress.com/2013/11/04/init/["Demystifying the init system (PID 1)"] blog article for a deep dive on PID 1 and [sysitem]#init# systems, as well.


*Cleaning Temporary Files*

Every temporary files you create during the build process should be removed. This includes any files added with the `ADD` command, too.  For example, it is strongly recommended you run the `yum clean` command after performing `yum install` operations.

If you craft your `RUN` statement as follows, you can prevent the `yum` cache from ending up in an image layer:

----
RUN yum -y install mypackage && yum -y install myotherpackage && yum clean all -y
----

Be aware that if you instead write:

----
RUN yum -y install mypackage
RUN yum -y install myotherpackage && yum clean all -y
----

Then the first `yum` invocation leaves extra files in that layer which cannot be removed by the later `yum clean` operation. The extra files are not visible in the final image, but they are present in the underlying layers.

The current Docker build process does not allow a command run in a later later to shrink the space used by the image when something was removed in an earlier layer. However, this may change in the future. This means that if you perform an `rm` command in a later layer, the files are hidden but it does not reduce the overall size of the image that needs to be downloaded. Therefore, as with the `yum clean` example, it is best to remove files in the same command that created them, where possible, so they do not end up written to a layer.

In addition, performing multiple commands in a single `RUN` statement reduces the number of layers in your image, which improves download and extraction time.

*Placing Instructions in Proper Order*

Docker reads the [sysitem]#Dockerfile# and runs the instructions from top to bottom. Every successfully executed instruction creates a layer which can be reused the next time this or another image is built. It is very important to place instructions that will rarely change at the top of your [sysitem]#Dockerfile#. Doing so ensures the next builds of the same image are very fast because the cache is not invalidated by upper layer changes.

For example, if you are working on a [sysitem]#Dockerfile# that contains an `ADD` command to install a file you are iterating on, and a `RUN` command to `yum install` a package, it is best to put the `ADD` command last:

----
FROM foo
RUN yum -y install mypackage && yum clean all -y
ADD myfile /test/myfile
----

This way each time you edit `myfile` and rerun `docker build`, the system reuses the cached layer for the `yum` command and only generates the new layer for the `ADD` operation.

If instead you wrote the [sysitem]#Dockerfile# as:

----
FROM foo
ADD myfile /test/myfile
RUN yum -y install mypackage && yum clean all -y
----

Then each time you changed `myfile` and reran `docker build`, the `ADD` operation would invalidate the `RUN` layer cache, so the `yum` operation would need to be rerun as well.

*Using `EXPOSE` to Mark Important Ports*

See the "Always `EXPOSE` Important Ports" section of the http://www.projectatomic.io/docs/docker-image-author-guidance[Project Atomic documentation] for more information.

*Setting Environment Variables with `ENV`*

It is good practice to set environment variables with the `ENV` instruction. One example is to set the version of your project. This makes it easy for people find the version without looking at the [sysitem]#Dockerfile#. Another example is advertising a path on the system that could be used by another process, such as `JAVA_HOME`.

*Avoiding Default Passwords*

Do not set default passwords. Many people will extend the image and forget to remove or change the default password. This can lead to security issues if there is a user with a well-known password in production. Passwords should be configurable using an environment variable instead. See the link:#using-env-vars[Using Environment Variables for Configuration] topic for more information.

If you do choose to set a default password, ensure that an appropriate warning message is displayed when the container is started. The message should inform the user of the value of the default password and explain how to change it, such as what environment variable to set.

*Avoiding SSHD*

Do not start or install SSHD in your image. For accessing running containers, you can use the `docker exec` command locally, or the OpenShift tooling which allows execution of arbitrary commands in running images. Installing and running SSHD in your image opens up additional vectors for attack and requirements for security patching.

*Using Volumes for Persisted Data*

Images should expect to use a https://docs.docker.com/reference/builder/#volume[Docker volume] for persisted data. Doing so allows OpenShift to mount network storage to the node where the container is running, then reattach that storage at a new node if the container moves. By using the volume for all persisted storage needs, the content is preserved throughout container restarts and moves. If your image writes data to arbitrary locations within the container, there is no guarantee that content will be preserved.

All data which is expected to live longer than the container must be written to a volume. With Docker 1.5, there will be a `readonly` flag for containers which can be used to strictly enforce good practices about not writing data to ephemeral storage in a container. Designing your image around that capability now will make it easier to take advantage of it later.

Furthermore, explicitly defining volumes in your [sysitem]#Dockerfile# makes it easy for consumers of the image to understand what volumes they need to define when running your image.

See the https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md[Kubernetes documentation] for more information on how volumes are used in OpenShift.

////
For more information on how Volumes are used in OpenShift, see https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md[this documentation]. (NOTE to docs team:  this link should really go to something in the openshift docs, once we have it)
////

NOTE: Even with persisted volumes, each instance of your image has its own volume, and the filesystem is not shared between instances.  This means the volume cannot be used to share state in a cluster.

== OpenShift-Specific Guidelines
The following are guidelines that apply when creating Docker images specifically for use on OpenShift.

*Enabling Images for Source-To-Image (STI)*

For images that are intended to run application code provided by a third party, such as a Ruby image designed to run Ruby code provided by a developer, you can enable your image to work with the https://github.com/openshift/source-to-image[Source-to-Image (STI)]  build tool. STI is a framework which makes it easy to write images that take application source code as an input and produce a new image that runs the assembled application as output.

For example, this https://github.com/openshift/wildfly-8-centos[Wildfly image] defines STI scripts which run a `maven` build on a Java source repository and copy the resulting [sysitem]#war# file into the Wildfly deployments directory. The resulting image now automatically starts Wildfly with the application running.

For more details about how to write STI scripts for your image, see the link:sti.html[STI Requirements] topic.

[[using-services]]
*Using Services for Inter-image Communication*

For cases where your image needs to communicate with a service provided by another image, such as a web front end image that needs to access a database image to store and retrieve data, your image should consume an OpenShift link:../architecture/kubernetes_model.html#service[service]. Services provide a static endpoint for access which does not change as containers are stopped, started, or moved. In addition, services provide load balancing for requests.

////
For more information see https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md[this documentation].  (NOTE to docs team:  this link should really go to something in the openshift docs once we have it)
////

*Providing Common Libraries*

For images that are intended to run application code provided by a third party, ensure that your image contains commonly used libraries for your platform. In particular, provide database drivers for common databases used with your platform. For example, provide JDBC drivers for MySQL and PostgreSQL if you are creating a Java framework image. Doing so prevents the need for common dependencies to be downloaded during application assembly time, speeding up application image builds. It will also simplify the work required by application developers to ensure all of their dependencies are met.

[[using-env-vars]]
*Using Environment Variables for Configuration*

Users of your image should be able to configure it without having to create a downstream image based on your image. This means that the runtime configuration should be handled using environment variables.
For a simple configuration, the running process can consume the environment variables directly. For a more complicated configuration or for runtimes which do not support this, configure the runtime by defining a template configuration file which is processed during startup. During this processing, values supplied using environment variables can be substituted into the configuration file or used to make decisions about what options to set in the configuration file.

It is also possible and recommended to pass secrets such as certificates and keys into the container using environment variables. This ensures that the secret values do not end up committed in an image and leaked into a Docker registry.

Providing environment variables allows consumers of your image to customize behavior, such as database settings, passwords, and performance tuning, without having to introduce a new layer on top of your image. Instead, they can simply define environment variable values when defining a pod and change those settings without rebuilding the image.

For extremely complex scenarios, configuration can also be supplied using volumes which are expected to be mounted into the container at runtime. If you take this path, your image should provide clear error messages on startup when the necessary volume or configuration is not present.

This topic ties in with the link:#using-services[Using Services for Inter-image Communication] topic in that configuration like datasources should be defined in terms of environment variables which provide the service endpoint information. This allows an application to dynamically consume a datasource service that is defined in the OpenShift environment without modifying the application image.

In addition, tuning should be done by inspecting the [sysitem]#cgroups# settings for the container. This allows the image to tune itself to the available memory, CPU, and other resources. For example, Java-based images should tune their heap based on the [sysitem]#cgroup# maximum memory parameter to ensure they do not exceed the limits and get an out-of-memory error.

See the following references for more on how to manage [sysitem]#cgroup# quotas in Docker containers:

- https://goldmann.pl/blog/2014/09/11/resource-management-in-docker
- https://docs.docker.com/articles/runmetrics
- http://fabiokung.com/2014/03/13/memory-inside-linux-containers

*Clustering*

Give careful thought to what it means to run multiple instances of your image. In the simplest case, the load balancing function of a service handles routing traffic to all instances of your image.  However, many frameworks need to share information in order to perform leader election or failover state, for example in session replication.

Consider how your instances accomplish this when running in OpenShift. Pods can communicate directly with each other, however their IP addresses change anytime the pod stops, starts, or moves, so your clustering scheme must be very dynamic.

*Logging*

Send all logging to standard out. OpenShift collects standard out from containers and sends it to the centralized logging service where it can be viewed. If you need to separate log content, prefix the output with an appropriate keyword, which makes it possible to filter the messages.

If your image logs to a file, users must use manual operations to enter the running container and retrieve or view the log file.

== External References
* https://docs.docker.com/articles/basics[Docker basics]
* https://docs.docker.com/reference/builder[Dockerfile reference]
* http://www.projectatomic.io/docs/docker-image-author-guidance[Project Atomic Guidance for Docker Image Authors]
