= Guidelines
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title: 

toc::[]

== Overview
When creating Docker images to run on OpenShift there are a number of best practices to consider in order to ensure consumers of those images have a good experience.  Since images are intended to be immutable and used as is, it is the image author's responsibility to ensure the image contains any artifacts that would typically be needed by a user of the image and that the image can be configured by the user.  Here are some general comments around things to consider.

== General Docker Best Practices
The following are some guidelines that apply to Docker image creation in general, independent of whether the images are used on OpenShift v3.

=== Reuse images
Whereever possible you should base your image on an appropriate upstream image via the `FROM` statement.  This will ensure that your image can easily pick up security fixes
from an upstream image when it is updated, rather than you being responsible for updating your dependencies directly.  

In addition, you should use tags in the `FROM` instruction (for example `rhel:rhel7`) will make it clear to users exactly which version of an image your image is based on.  If you use a tag other than `latest` this ensures that your image is not subjected to breaking changes that might go into the `latest` version of an upstream image.

=== Tagging images
When tagging your own images, you should strive to maintain backwards compatibility within a tag.  For example, if you provide an image named "foo" and it currently includes version 1.0, you might provide a tag of "foo:v1".  When you update the image, as long as it continues to be compatible with the orginal image, you can continue to tag the new image "foo:v1" and downstream consumers of this tag will be able to get updates without being broken.  If you come out with an incompatible update, then you should switch to a new tag, e.g. "foo:v2".  This allows downstream consumers to move up to the new version at will, but not be inadvertently broken by the new incompatible image.

Of course any downstream consumer who chooses to use "foo:latest" will be taking on the risk of any incompatible changes introduced.


=== Do not start multiple processes
It is not a good idea to start multiple services (like database, sshd, …​) inside one container. Containers are lighweight and can be easily linked together for multiprocess orchestration.  OpenShift allows you to easily colocate and comanage related images by grouping them into a single pod.  This will ensure they share a network namespace and storage for communication.  It also makes updates less disruptive as each image can be updated less frequently and independently.  Having a single process also makes signal handling flows clearer as you do not need to manage routing signals to spawned processes.


=== Use exec in wrapper scripts
See http://www.projectatomic.io/docs/docker-image-author-guidance/, subsection _Always `exec` in Wrapper Scripts_

Also be aware that your process runs as PID 1 when running in a Docker container.  This means that if your main process terminates, the entire container will be stopped, killing any child processes you may have launched from your PID 1 process.  Additional implications to be aware of are documented http://blog.phusion.nl/2015/01/20/docker-and-the-pid-1-zombie-reaping-problem/[here].  For a deep dive on PID 1 and init systems, you can read https://felipec.wordpress.com/2013/11/04/init/[this] as well.


=== Clean temporary files
Every temporary files you create during the build process should be removed. This includes any files added with the ADD command too.  For example it is strongly recommended you run yum clean after performing yum install operations.  If you craft your `RUN` statement as follows, you an prevent the yum cache from ending up in an image layer:

	RUN yum -y install mypackage && yum -y install myotherpackage && yum clean all -y

Be aware that if you instead write:
		
		RUN yum -y install mypackage
		RUN yum -y install myotherpackage && yum clean all -y

Then the first `yum` invocation will leave extra files in that layer which cannot be removed by the later clean operation.  (The extra files will not be visible in the final image but they will be present in the underlying layers).

Although the current Docker build process does not allow shrinking the space used by the image when we remove something from an earlier layer by a command run in a later layer, this may change in the future.   This means that if you perform an `rm` command in a later layer, you will hide the files but you will not reduce the overall size of the image that needs to be downloaded.  Therefore, as with the yum clean example, it's best to remove files in the same command that created them, where possible, so they do not end up written to a layer.  

In addition, performing multiple commands in a single `RUN` statement will reduce the number of layers in your image which will improve download and extraction time.


=== Place instructions in proper order
Docker reads the Dockerfile and runs the instructions from top to bottom. Every successfully executed instruction creates a layer which can be reused next we build this (or other image). It is very important to place on top of your Dockerfile instructions that will change rarely.

This will make sure the next builds of the same image will be very fast because the cache will not be invalidated by upper layer changes.

For example, if you are working on a Dockerfile that contains an `ADD` command to install a file you are iteratin on, and a `RUN` command to yum install a package, it's best to put the `ADD` command last, such as:

		FROM foo
		RUN yum -y install mypackage && yum clean all -y
		ADD myfile /test/myfile

This way each time you edit `myfile` and rerun `docker build` the system will reuse the cached layer for the yum command and only have to generate the new layer for the `ADD` operation.

If instead you wrote the Dockerfile as:

		FROM foo
		ADD myfile /test/myfile
		RUN yum -y install mypackage && yum clean all -y

Then each time you changed `myfile` and reran `docker build`, the `ADD` operation would invalidate the `RUN` layer cache so the yum operation would need to be rerun as well.

=== Use EXPOSE to mark important ports
See http://www.projectatomic.io/docs/docker-image-author-guidance/, subsection _Always `EXPOSE` Important Ports_

=== Set environment variables with ENV
It’s a good idea to set environment variables with the `ENV` instruction. One example is to set version of your project. This will make it easy for people find the version without even looking at the Dockerfile.  Another example of an environment variable worth setting is when to advertise some path on the system that could be used by some process, like `JAVA_HOME`.

=== Do not set default passwords
It is not a good idea to set default passwords. Many people will extend the image and forget to remove or change the default password. This will lead to security issues where in production there will be a user with a well-known passwords. Passwords should be configurable via environment variable instead (See anchor:configuration[])

If you do choose to set a default password, ensure that an appropriate warning message is displayed when the container is started.  The message should inform the user of the value of the default password and explaining how to change it (e.g. what environment variable to set).

=== Do not start (or install) SSHD
Running SSHD should be avoided.  For accessing running containers you can use `docker exec` locally, or the OpenShift tooling which allows execution of arbitrary commands in running images.  Installing and running SSHD in your image opens up additional vectors for attack and requirements for security patching.

=== Use Volumes for Persisted Data
Images should expect to use a https://docs.docker.com/reference/builder/#volume[Docker volume] for persisted data.  This way the OpenShift system can mount network storage to the node where the container is running and then reattach that storage at a new node if the container moves.  By using the volume for all persisted storage needs, the content will be preserved throughout container restarts and moves.  If your image writes data to arbitrary locations within the container, there is no guarantee that content will be preserved.

All data which is expected to live longer than the container must be written to a volume.  With Docker 1.5 there will be a `readonly` flag for containers which can be used to strictly enforce good practices about not writing data to ephemeral storage in a container, so designing your image around that capability now will make it easier to take advantage of it later.

Furthermore, by explicitly defining volumes in your Dockerfile, you make it easy for consumers of the image to understand what volumes they need to define when running your image.

For more information on how Volumes are used in OpenShift, see https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/volumes.md[this documentation]. (NOTE to docs team:  this link should really go to something in the openshift docs, once we have it)

Keep in mind that even with persisted volumes, each instance of your image will have its own volume, the filesystem is not shared between instances.  This means the volume cannot be used to share state in a cluster.



== OpenShift Specific Recommendations
=== Enable images for Source-To-Image
For images that are intended to run application code provided by a third party (e.g. a Ruby image designed to run Ruby coded provided by a developer), you should enable your image to work with the https://github.com/openshift/source-to-image[Source to Image] (STI) build tool.  It is a framework which makes it easy to write images that take application source code as an input, and produce a new image that will run the assembled application as output.  For example, this https://github.com/openshift/wildfly-8-centos[Wildfly] image defines STI scripts which will run a `maven` build on a java source repository and copy the resulting war file into the Wildfly deployments directory.  The resulting image will now automatically start Wildfly with the application running.

For more details about how to write STI scripts for your image, see the https://github.com/openshift/source-to-image/blob/master/docs/builder_image.md[STI documentation].

=== Use Services for inter-image communication
For cases where your image needs to communicate with a service provided by another image (e.g. a web frontend image that needs to access a database image to store/retrieve data), your image should consume an OpenShift Service.  Services provide a static endpoint for access which will not change as containers are stopped/started/moved.  In addition services provide load balancing for requests.  For more information see https://github.com/GoogleCloudPlatform/kubernetes/blob/master/docs/services.md[this documentation].  (NOTE to docs team:  this link should really go to something in the openshift docs once we have it)

=== Provide common libraries
For images that are intended to run application code provided by a third party, ensure that your image contains commonly used libraries for your platform.  In particular, provide database drivers for common databases used with your platform (e.g. provide JDBC drivers for MySQL and PostgreSQL if you are creating a java framework image).  This will prevent the need for common dependencies to be downloaded during application assembly time, speeding up application image builds.  It will also simplify the work application authors need to do to ensure all their dependencies are met.

=== Configuration
Users of your image should be able to configure it without having to create a downstream image based on your image.  This means that runtime configuration should be handled via environment variables.  For simple configuration, the running process can consume the environment variables directly.  For more complicated configuration or for runtimes which do not support this, you should configure the runtime by defining a template configuration file which is processed during startup.  During this processing, values supplied via environment variable can be substituted into the configuration file or used to make decisions about what options to set in the configuration file.

It is even possible (and recommended) to pass secrets such as certificates and keys into the container via environment variable.  This ensures that the secret values do not end up committed in an image and leaked into a docker registry.

This allows consumers of your image to customize behavior (e.g. database settings, passwords, performance tuning) without having to introduce a new layer on top of your image.  Instead, they can simply define environment variable values when defining a pod, and change those settings without rebuilding the image.

For extremely complex scenarios, configuration can also be supplied via volumes which are expected to be mounted into the container at runtime.  If you take this path, your image should provide clear error messages on startup when the necessary volume or configuration is not present.

This topic ties in with using services for inter-image communication in that configuration like datasources should be defined in terms of environment variables which provide the service endpoint information.  In this way, an application can dynamically consume a datasource service that is defined in the OpenShift environment without modifying the application image.

In addition, tuning should be done by inspecting the cgroups settings for the container.  This will allow the image to tune itself to the available memory, CPU, etc.  For example java based images should tune their heap based on the cgroup maximum memory parameter to ensure they do not exceed the limits and get an out of memory error.

Here are some useful references on how to manage cgroup quotas in Docker containers:

* https://goldmann.pl/blog/2014/09/11/resource-management-in-docker/
* https://docs.docker.com/articles/runmetrics/
* http://fabiokung.com/2014/03/13/memory-inside-linux-containers/

=== Clustering
Give careful thought to what it means to run multiple instances of your image.  In the simplest case the load balancing function of a service will handle routing traffic to all instances of your image.  However, many frameworks need to share information in order to perform leader election or failover state (e.g. session replication).  Consider how your instances will accomplish this when running in OpenShift.  Pods can communicate directly with each other, however their IP addresses will change anytime the pod stops/starts/moves, so your clustering scheme needs to be very dynamic.

=== Logging
All logging should be sent to standard out.  OpenShift will collect standard out from containers and send it to the centralized logging service where it can be viewed.  If you need to seperate log content, prefix the output with an appropriate keyword which will make it possible to filter the messages.

If your image logs to a file, users will need to use manual operations to enter the running container and retrieve/view the log file.

== External References
* https://docs.docker.com/articles/basics/[Docker basics]
* https://docs.docker.com/reference/builder/[Dockerfile reference]
* http://www.projectatomic.io/docs/docker-image-author-guidance/[Project Atomic image author guidance]