// Module included in the following assemblies:
//
// * serverless/release-notes.adoc

[id="serverless-rn-1-8-0_{context}"]

= Release Notes for Red Hat {ServerlessProductName} 1.8.0

[id="new-features-1-8-0_{context}"]
== New features

* {ServerlessProductName} now uses Knative Serving 0.14.1.
* {ServerlessProductName} now uses Knative Serving Operator 0.14.0.
* {ServerlessProductName} now uses Knative `kn` CLI 0.14.0.
* {ServerlessProductName} uses Knative Eventing 0.14.2.
* {ServerlessProductName} now uses Knative Eventing Operator 0.14.0.
* {ServerlessProductName} now uses Kourier 0.14.1.

// [id="fixed-issues-1-8-0_{context}"]
// == Fixed issues

[id="known-issues-1-8-0_{context}"]
== Known issues
* Knative Serving has a fixed, minimum CPU request of `25m` for the `queue-proxy` setting.
If your cluster has any value set that conflicts with this, for example, if you have set a minimum CPU request for `defaultRequest` of more than `25m`, the Knative service fails to deploy.
As a workaround, you can configure the `resourcePercentage` annotation individually for your Knative services.
+
.Example resourcePercentage configuration
[source,yaml]
----
spec:
  template:
    metadata:
      annotations:
        queue.sidecar.serving.knative.dev/resourcePercentage: "10" <1>
----

+
<1> `queue.sidecar.serving.knative.dev/resourcePercentage` is the percentage of user container resources to be used for `queue-proxy`. This can be between a range of 0.1 - 100.

* On {product-title} 4.5 and newer versions, deploying a Knative service with traffic distribution shows an invalid URL for the general service address in the *Developer* perspective of the web console.
+
The correct URL is shown in YAML resources and CLI command outputs.

* If you use a ping source with {ServerlessProductName}, after you uninstall and delete all other Knative Eventing components, the `pingsource-jobrunner` `Deployment` resource is not deleted.

* If you delete a sink before you delete the sink binding connected to it, the `SinkBinding` object deletion might hang.
+
As a workaround, you can edit the `SinkBinding` object and remove the finalizer that causes the hanging:
+
[source,yaml]
----
  finalizers:
   - sinkbindings.sources.knative.dev
----

* The sink binding behavior has changed in {ServerlessProductName} 1.8.0, which breaks backwards compatibility.
+
To use sink binding, cluster administrators must now label the namespace configured in the `SinkBinding` object with `bindings.knative.dev/include:"true"`.
+
Resources configured in the `SinkBinding` object must also be labeled with `bindings.knative.dev/include:"true"`; however, this task can be completed by any {ServerlessProductName} user.
+
. As a cluster administrator, you can label the namespace by entering the following command:
+
[source,terminal]
----
$ oc label namespace <namespace> bindings.knative.dev/include=true
----
+
. Users must manually add a `bindings.knative.dev/include=true` label to resources.
+
For example, to add this label to a `CronJob` object, add the following lines to the Job resource YAML definition:
+
[source,yaml]
----
  jobTemplate:
    metadata:
      labels:
        app: heartbeat-cron
        bindings.knative.dev/include: "true"
----
