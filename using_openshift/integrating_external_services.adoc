= Integrating External Services
{product-author}
{product-version}
:data-uri:
:icons:
:experimental:
:toc: macro
:toc-title:

toc::[]

== Overview

Many OpenShift applications use external resources (external databases, external SaaS endpoints,
etc).  These external resources are simple to model as native OpenShift services so that 
applications can work with them as they would any other internal service.

== Example: External SaaS Provider

One of the most common types of external services is an external SaaS endpoint.  As an example,
assume that you want to use a SaaS provider for which an application needs:

1. An endpoint to communicate with
2. A set of credentials:
   a.  An API key
   b.  A username
   c.  A passphrase

The formula for integrating with this type of external resource is fairly simple.  The pieces of
the solution are:

1.  A `Service` object to represent the SaaS provider as an OpenShift service
2.  One or more `Endpoints` for the service
3.  Environment variables in the appropriate pods that contain the credentials

=== Creating the service

The first step in integrating with an external service is to create an OpenShift service to
represent it.  The `Service` resource can express external services by having an empty `Selector`
field:

----
{
  "kind": "Service",
  "apiVersion": "v1beta3",
  "metadata": {
    "name": "external-service"
  },
  "spec": { <1>
    "port": 1234
  }
}
----

<1> The service spec must have no `selector` field

=== Setting the endpoints

The next step is to create endpoints for the service.  This will give the service proxy and router
information about where to send traffic going to the service:

----
{
  "kind": "Endpoints",
  "apiVersion": "v1beta3",
  "metadata": {
    "name": "external-service" <1>
  },
  "endpoints": [ <2>
    "api.mysaas.com:80",
    "api2.mysaas.com:8080"
  ]
}
----

<1> The name must match the name of the `Service` instance
<2> Traffic to the service will be load-balanced between the supplied `Endpoints`

=== Consuming credentials in pods

Now that the service and endpoints are defined, we need to give pods the credentials to use the
service.  This is done by setting environment variables in the appropriate containers.  In this
example, the container will receive the following environment variables with credentials for the
service:

1.  `MY_SAAS_API_KEY`: Holds the API key to use with the service
2.  `MY_SAAS_USERNAME`: Holds the username to use with the service
3.  `MY_SAAS_PASSPHRASE`: Holds the passphares to use with the service

----
{
  "kind": "DeploymentConfig",
  "apiVersion": "v1beta1",
  "metadata": {
    "name": "my-app-deployment"
  },
  "template": { <1>
    "controllerTemplate": {
      "replicas": 1,
      "replicaSelector": {
        "name": "frontend"
      },
      "podTemplate": {
        "desiredState": {
          "manifest": {
            "version": "v1beta1",
            "containers": [
              {
                "name": "helloworld",
                "image": "openshift/openshift/origin-ruby-sample",
                "ports": [
                  {
                    "containerPort": 8080
                  }
                ],
                env: [
              	  {
              	    "name": "SAAS_API_KEY"
              	    "value": "<SaaS service API key>"
              	  },
              	  {
              	    "name": "SAAS_USERNAME"
              	    "value": "<SaaS service user>"
              	  },
              	  {
              	    "name": "SAAS_PASSPHRASE"
              	    "value": "<SaaS service passphrase>"
              	  },
                ]
              }
            ]
          }
        },
        "labels": {
          "name": "frontend"
        }
      }
    }
  },
}
----

<1> Other fields on the `DeploymentConfig` are omitted
