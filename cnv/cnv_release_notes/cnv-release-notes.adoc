[id="cnv-release-notes"]
= {RN_BookName}
include::modules/cnv-document-attributes.adoc[]
:context: cnv-release-notes
toc::[]


== About {ProductName}

include::modules/cnv-what-you-can-do-with-cnv.adoc[leveloffset=+2]

=== {ProductName} support

:FeatureName: {ProductName}
include::modules/technology-preview.adoc[leveloffset=+2]

== New and changed features

=== Supported binding methods
* Open vSwitch (OVS) is no longer recommended and should not be used
in {ProductName} 2.0.
* For the default Pod network, `masquerade` is the only recommended binding
method. It is not supported for non-default networks.
* For secondary networks, use the `bridge` binding method.

=== Web console improvements
* You can now view all services associated with a virtual machine in the
*Virtual Machine Details* screen.


== Resolved issues

* Deleting a PVC after a CDI import fails no longer results in the importer Pod
getting stuck in a `CrashLoopBackOff` state. The PVC is now deleted normally.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1673683[*BZ#1673683*])


== Known issues

* Some KubeVirt resources are improperly retained when removing {ProductName}.
As a workaround, you must manually remove them by running the command
`oc delete apiservices v1alpha3.subresources.kubevirt.io -n kubevirt-hyperconverged`.
These resources will be removed automatically after
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1712429[*BZ#1712429*]) is
resolved.

* When using an older version of `virtctl` with {ProductName} 2.0, `virtctl`
cannot connect to the requested virtual machine. On the client, update the
`virtctl` RPM package to the latest version to resolve this issue.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1706108[*BZ#1706108*])

* Interfaces connected to the default Pod network lose connectivity after
live migration. As a workaround, use an additional `multus`-backed network.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1693532[*BZ#1693532*])

* {ProductName} cannot reliably identify node drains that are triggered by
running either `oc adm drain` or `kubectl drain`. Do not run these commands on
the nodes of any clusters where {ProductName} is deployed. The nodes might not
drain if there are virtual machines running on top of them.
The current solution is to put nodes into maintenance.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1707427[*BZ#1707427*])

* If you create a virtual machine with the Pod network connected in `bridge`
mode and use a `cloud-init` disk, the virtual machine will lose its network
connectivity after being restarted. As a workaround, remove the `HWADDR` line
in the file `/etc/sysconfig/network-scripts/ifcfg-eth0`.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1708680[*BZ#1708680*])
+
[NOTE]
====
Avoid this issue by using the recommended `masquerade` binding method for
the default Pod network.
====

* If a virtual machine uses guaranteed CPUs, it will not be scheduled, because
the label `cpumanager=true` is not automatically set on nodes. As a
workaround, remove the `CPUManager` entry from the `kubevirt-config` ConfigMap.
Then, manually label the nodes with `cpumanager=true` before running virtual
machines with guaranteed CPUs on your cluster.
(link:https://bugzilla.redhat.com/show_bug.cgi?id=1718944[*BZ#1718944*])